# This file is covered by the LICENSE file in the root of this project.

#Training & Experiment params
training:
  n_epochs: 100
  lr: 1.e-6
  batch_size: 8
  test: False
  gpu_ids: [0]
  checkpoints_dir: './checkpoints_kitti_360'
  epoch: 'latest'
  continue_train: False
  display_freq: 20000
  print_freq: 50
  save_latest_freq: 1000
  verbose: False
  seed: 6
  lr_policy: 'identity'
  lr_decay_iters: 10000000
  beta1: 0.5

# model params
model:
  name: 'vqgan'
  modality_A: ['depth']
  modality_B: ['depth']
  out_ch: ['depth', 'mask']
  norm_label: False
  augment: ['row_drop', 'col_drop']
  vqmodel:
    embed_dim: 256
    n_embed: 1024
    ddconfig:
      has_attention: False
      symmetric: True
      double_z: False
      z_channels: 256
      resolution: 256
      in_channels: 1
      out_ch: 2
      ch: 128
      # ch_mult: [1,1,2,2,4]  # num_down = len(ch_mult)-1
      ch_mult: [1,1,2,2]  # num_down = len(ch_mult)-1
      num_res_blocks: 1
      attn_resolutions: [32]
      dropout: 0.2
    lossconfig:
      target: models.modules.losses.vqperceptual.VQLPIPSWithDiscriminator
      params:
        lambda_mask: 0.1
        perceptual_weight: 0.0
        disc_conditional: False
        disc_in_channels: 1
        disc_start: 0
        disc_weight: 0.0
        codebook_weight: 1.0
        lambda_nd: 0.0



# dataset params
dataset:
  dataset_A:
    name: 'kitti_360'
    modality: ['depth']
    fill_in_label: True
    do_gp: False
    img_prop:
      width: 1024
      height: 64
      finesize: -1
