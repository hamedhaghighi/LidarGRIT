# This file is covered by the LICENSE file in the root of this project.

#Training & Experiment params
training:
  n_epochs: 100
  lr: 4.5e-6
  batch_size: 1
  test: False
  gpu_ids: [0]
  checkpoints_dir: './new_checkpoints_trans'
  epoch: 'best'
  continue_train: False
  display_freq: 20000
  print_freq: 50
  save_latest_freq: 1000
  verbose: False
  suffix : ''
  seed: 6
  lr_policy: 'identity'
  lr_decay_iters: 10000000
  beta1: 0.5

# model params
model:
  name: 'transformer'
  norm_label: False
  raster_type: 'p2p'
  vq_ckpt_path: ./checkpoints/d53e32e5e14b6a4b997746f8e0bd480367fefe955c0097d40322835a342d82f8/best.pth
  transformer_config:
    n_layer: 6
    n_head: 8
    n_embd: 256
    embd_pdrop: 0.2
    resid_pdrop: 0.0
    attn_pdrop: 0.0
  cond_stage_config:
    target: models.modules.misc.coord.CoordStage
    params:
      n_embed: 1024
      down_factor: 16



# dataset params
dataset:
  dataset_A:
    name: 'kitti'
    modality: ['depth']
    fill_in_label: True
    do_gp: False
    img_prop:
      width: 256
      height: 64
      finesize: -1
